{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is a kaggle competition:\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges aim to predict the final price of each home.\n",
    "\n",
    "Random forest regression, linear regression, lasso regression, and xgboost are performed and results are written in seprate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "y_train=train[\"SalePrice\"]\n",
    "# Labelindex=train.columns.get_loc(\"SalePrice\")\n",
    "x_train=train.drop([\"SalePrice\"], axis=1)\n",
    "\n",
    "#Keep column Id for output\n",
    "IdTest=pd.DataFrame(test['Id'])\n",
    "IdTest.columns =['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes\n",
    "obj_df = train.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()\n",
    "# obj_df[obj_df.isnull().any(axis=1)]\n",
    "\n",
    " \n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "x_train=imp.fit_transform(x_train)\n",
    "test=imp.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA for feature reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.11556429e+02, -2.14000529e+02,  2.16212543e+02, ...,\n",
       "        -6.23138176e-02,  2.68360578e-01, -1.52067532e-01],\n",
       "       [-7.34023594e+02, -5.35635115e+00,  3.24440568e+02, ...,\n",
       "         5.18993445e-01,  3.63570209e-01,  1.26484763e-01],\n",
       "       [-7.32872338e+02,  7.71530495e+01,  2.59561309e+01, ...,\n",
       "        -1.10588030e-02,  1.79512793e-02, -1.87074364e-01],\n",
       "       ...,\n",
       "       [ 7.12069818e+02,  2.32046528e+02, -3.33854895e+02, ...,\n",
       "        -4.00526354e-01, -6.51314704e-01,  7.05793174e-01],\n",
       "       [ 7.43273411e+02, -1.54748721e+02,  1.85502683e+02, ...,\n",
       "        -1.02672634e+00,  6.18045574e-01, -1.51936169e+00],\n",
       "       [ 7.20347998e+02,  9.44045822e+01,  3.73019641e+02, ...,\n",
       "         2.71224953e-01, -6.26060001e-01,  4.29664427e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(x_train)\n",
    "x_train = pca.transform(x_train) # transformed data\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Categorical Values to numerical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_style = OrdinalEncoder()\n",
    "x_train = oe_style.fit_transform(x_train)\n",
    "test=oe_style.fit_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicting values and Making outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf.predict(test)\n",
    "xs=pd.DataFrame(predictions,columns=['SalePrice'])\n",
    "x=IdTest['Id']\n",
    "y= xs[\"SalePrice\"]\n",
    "z=pd.concat([x,y], axis=1, ignore_index=True)\n",
    "z.columns =['Id','SalePrice']\n",
    "z.to_csv('RandomForest.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)\n",
    "predictions=rf_random.predict(test)\n",
    "xs=pd.DataFrame(predictions,columns=['SalePrice'])\n",
    "x=IdTest['Id']\n",
    "y= xs[\"SalePrice\"]\n",
    "z=pd.concat([x,y], axis=1, ignore_index=True)\n",
    "z.columns =['Id','SalePrice']\n",
    "z.to_csv('RandomForestOptimal.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 100,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using other regression models: linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "predictions=reg.predict(test)\n",
    "xs=pd.DataFrame(predictions,columns=['SalePrice'])\n",
    "x=IdTest['Id']\n",
    "y= xs[\"SalePrice\"]\n",
    "z=pd.concat([x,y], axis=1, ignore_index=True)\n",
    "z.columns =['Id','SalePrice']\n",
    "z.to_csv('linearResult1.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# create an xgboost regression model\n",
    "model = XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "model.fit(x_train, y_train)\n",
    "predictions=model.predict(test)\n",
    "xs=pd.DataFrame(predictions,columns=['SalePrice'])\n",
    "Id=IdTest['Id']\n",
    "salePrice= xs[\"SalePrice\"]\n",
    "combine=pd.concat([Id,salePrice], axis=1, ignore_index=True)\n",
    "combine.columns =['Id','SalePrice']\n",
    "combine.to_csv('XgboostResult2.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using other regression models: lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso()\n",
    "lasso.fit(x_train, y_train)\n",
    "predictions=lasso.predict(test)\n",
    "xs=pd.DataFrame(predictions,columns=['SalePrice'])\n",
    "Id=IdTest['Id']\n",
    "salePrice= xs[\"SalePrice\"]\n",
    "combine=pd.concat([Id,salePrice], axis=1, ignore_index=True)\n",
    "combine.columns =['Id','SalePrice']\n",
    "combine.to_csv('lassoResult.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates train eror\n",
    "print(\"R_Squared_test_Error:\", r2_score(y_test, y_pred))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, predictions))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
